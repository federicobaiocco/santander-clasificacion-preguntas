{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from spacy.lang.es import Spanish\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from multiprocessing import  Pool\n",
    "import numpy as np\n",
    "import fasttext\n",
    "import csv\n",
    "import unicodedata\n",
    "from collections import defaultdict\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "data_train = pd.read_csv('./train.csv', sep='|')\n",
    "data_test = pd.read_csv('./test_santander.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train[data_train.Intencion != 'Cat_104']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text,nlp):\n",
    "    s = []\n",
    "    for tok in nlp.tokenizer(text.lower()):\n",
    "        if not tok.is_stop:\n",
    "            if tok.is_alpha and not (tok.is_digit or len(tok.text) == 1):\n",
    "                if not tok.is_ascii:\n",
    "                    tok = ''.join(c for c in unicodedata.normalize('NFD', tok.text.lower()) if unicodedata.category(c) != 'Mn')\n",
    "                    s.append(tok)\n",
    "                else:\n",
    "                    s.append(tok.text)\n",
    "    if not s:\n",
    "        return \"emptystring\"\n",
    "    else:\n",
    "        s = ' '.join(s)\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_es = Spanish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tk = nlp_es.tokenizer('para, 1983, de con 18te ')\n",
    "#for t in tk:\n",
    "#    print(\"Text:\", t.text)\n",
    "#    print(\"Is Stop: \", t.is_stop)\n",
    "#    print(\"Is Ascii: \", t.is_ascii)\n",
    "#    print(\"Is Alpha: \", t.is_alpha)\n",
    "#    print(\"Is Digit: \", t.is_digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallelize_dataframe(df, func, n_cores=8):\n",
    "    df_split = np.array_split(df, n_cores)\n",
    "    pool = Pool(n_cores)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    nlp_es = Spanish()\n",
    "    df[\"tokens\"] = df[\"Pregunta\"].apply(normalize_text,args=(nlp_es,))\n",
    "    df[\"label\"] = df[\"Intencion\"].apply(lambda x: '__label__'+ x)\n",
    "    return df[[\"label\",\"tokens\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_test(df):\n",
    "    nlp_es = Spanish()\n",
    "    df[\"tokens\"] = df[\"Pregunta\"].apply(normalize_text,args=(nlp_es,))\n",
    "    return df[[\"id\",\"tokens\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fasttext_split_files(train_df, test_df, outputfiles):\n",
    "    # train and validation set files\n",
    "    train = parallelize_dataframe(train_df, preprocess)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(train[[\"tokens\"]], train[\"label\"], test_size=0.2, random_state=42, stratify=train[\"label\"])\n",
    "    train_fasttext = pd.concat([y_train,X_train[\"tokens\"]], axis=1)\n",
    "    val_fasttext = pd.concat([y_val,X_val[\"tokens\"]], axis=1)\n",
    "    train_fasttext.to_csv(outputfiles[0],index=False, sep=' ', header=False, quoting=csv.QUOTE_NONE, quotechar=\"\", escapechar=\" \")\n",
    "    val_fasttext.to_csv(outputfiles[1],index=False, sep='|', header=False, quoting=csv.QUOTE_NONE, quotechar=\"\", escapechar=\" \")\n",
    "    \n",
    "    #test set file\n",
    "    if test_df is not None:\n",
    "        test = parallelize_dataframe(test_df, preprocess_test)\n",
    "        test.to_csv(outputfiles[2],index=False,header=False,line_terminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 164 ms, sys: 120 ms, total: 284 ms\n",
      "Wall time: 1.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "create_fasttext_split_files(data_train, data_test, ['./fastextData/train.csv','./fastextData/val.csv','./fastextData/test.csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "keyword can't be an expression (<unknown>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3331\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[1;32m\"<ipython-input-14-a0f1e57d4016>\"\u001b[0m, line \u001b[1;32m1\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    get_ipython().run_cell_magic('time', '', 'model = fasttext.train_supervised(input=\"./fastextData/train.csv\",autotune-validation=\\'./fastextData/val.csv\\',\\n                                  epoch=300, lr=0.1, wordNgrams=1, dim=300,\\n                                  thread=8)\\n')\n",
      "  File \u001b[1;32m\"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m2362\u001b[0m, in \u001b[1;35mrun_cell_magic\u001b[0m\n    result = fn(*args, **kwargs)\n",
      "  File \u001b[1;32m\"<decorator-gen-61>\"\u001b[0m, line \u001b[1;32m2\u001b[0m, in \u001b[1;35mtime\u001b[0m\n",
      "  File \u001b[1;32m\"/opt/conda/lib/python3.7/site-packages/IPython/core/magic.py\"\u001b[0m, line \u001b[1;32m187\u001b[0m, in \u001b[1;35m<lambda>\u001b[0m\n    call = lambda f, *a, **k: f(*a, **k)\n",
      "  File \u001b[1;32m\"/opt/conda/lib/python3.7/site-packages/IPython/core/magics/execution.py\"\u001b[0m, line \u001b[1;32m1268\u001b[0m, in \u001b[1;35mtime\u001b[0m\n    expr_ast = self.shell.compile.ast_parse(expr)\n",
      "\u001b[0;36m  File \u001b[0;32m\"/opt/conda/lib/python3.7/site-packages/IPython/core/compilerop.py\"\u001b[0;36m, line \u001b[0;32m101\u001b[0;36m, in \u001b[0;35mast_parse\u001b[0;36m\u001b[0m\n\u001b[0;31m    return compile(source, filename, symbol, self.flags | PyCF_ONLY_AST, 1)\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"<unknown>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m keyword can't be an expression\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "model = fasttext.train_supervised(input=\"./fastextData/train.csv\",autotune-validation='./fastextData/val.csv',\n",
    "                                  epoch=300, lr=0.1, wordNgrams=1, dim=300,\n",
    "                                  thread=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = pd.read_csv('./fastextData/val.csv', sep='|', names=['label','tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = model.predict(val_data.tokens.values.tolist(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "balanced_accuracy_score(val_data.label, np.array(val_preds)[0][:].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(\"./models/fasttext_model.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.load_model(\"./models/fasttext_baseline.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('./fastextData/test.csv',names=['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time \n",
    "predictions = model.predict(test_data[\"tokens\"].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.Series([x[0][13:] for x in predictions[0]])\n",
    "submission = pd.DataFrame({'id':test_data.index.values, 'pred': predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"./submissions/fastext_baseline_subm.csv\",header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-2-gpu.2-2.m49",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-gpu.2-2:m49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
